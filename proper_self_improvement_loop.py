#!/usr/bin/env python3
"""
Proper Self-Improvement Loop Implementation
Follows the exact 6-step process specified by the user
"""

import asyncio
import requests
import subprocess
import time
import os
import json
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pyautogui
import logging

logger = logging.getLogger(__name__)

class ProperSelfImprovementLoop:
    """Implements the exact 6-step self-improvement loop"""
    
    def __init__(self, server_url: str = "http://localhost:5004"):
        self.server_url = server_url
        self.project_path = "/Users/alangurung/Documents/MVP builds/PAAgent"
        self.current_performance = 5.0
        self.target_performance = 8.0
        self.improvement_cycle = 0
        
        # Git setup
        self.git_branch = "self-improvement"
        self.backup_branch = "backup-before-improvement"
        
        # Test scenarios for self-testing
        self.test_scenarios = [
            {
                "name": "revenue_pipeline",
                "input": "Show me our revenue pipeline and identify top 3 actions",
                "expected_elements": ["TechCorp", "DataInc", "CloudSys", "pipeline", "actions"],
                "target_score": 0.9
            },
            {
                "name": "urgent_priorities", 
                "input": "What's the most urgent issue and immediate action plan?",
                "expected_elements": ["urgent", "GitHub", "security", "immediate", "action"],
                "target_score": 0.9
            },
            {
                "name": "meeting_preparation",
                "input": "Prepare me for my next meeting with talking points",
                "expected_elements": ["meeting", "agenda", "talking points", "Q4", "revenue"],
                "target_score": 0.9
            }
        ]
    
    async def run_complete_self_improvement_cycle(self):
        """Run the complete 6-step self-improvement cycle"""
        
        print("ü§ñ STARTING COMPLETE SELF-IMPROVEMENT CYCLE")
        print("=" * 60)
        print("üìã Following exact 6-step process:")
        print("   1. SELF-TESTING")
        print("   2. SELF-EVALUATION") 
        print("   3. CODE ANALYSIS")
        print("   4. IMPROVEMENT (via Computer Use)")
        print("   5. TESTING")
        print("   6. COMMIT OR ROLLBACK")
        print("=" * 60)
        
        self.improvement_cycle += 1
        
        try:
            # STEP 1: SELF-TESTING
            print(f"\nüîÑ CYCLE {self.improvement_cycle} - STEP 1: SELF-TESTING")
            test_results = await self.step1_self_testing()
            
            # STEP 2: SELF-EVALUATION  
            print(f"\nüìä CYCLE {self.improvement_cycle} - STEP 2: SELF-EVALUATION")
            evaluation_results = await self.step2_self_evaluation(test_results)
            
            # STEP 3: CODE ANALYSIS
            print(f"\nüîç CYCLE {self.improvement_cycle} - STEP 3: CODE ANALYSIS")
            code_analysis = await self.step3_code_analysis(evaluation_results)
            
            # STEP 4: IMPROVEMENT (via Computer Use)
            print(f"\nüî® CYCLE {self.improvement_cycle} - STEP 4: IMPROVEMENT VIA COMPUTER CONTROL")
            improvement_result = await self.step4_computer_improvement(code_analysis)
            
            # STEP 5: TESTING
            print(f"\nüß™ CYCLE {self.improvement_cycle} - STEP 5: TESTING")
            test_passed = await self.step5_testing(test_results)
            
            # STEP 6: COMMIT OR ROLLBACK
            print(f"\nüíæ CYCLE {self.improvement_cycle} - STEP 6: COMMIT OR ROLLBACK")
            final_result = await self.step6_commit_or_rollback(test_passed, improvement_result)
            
            # Check if we should continue
            if evaluation_results['overall_score'] >= 0.8:
                print(f"\nüéâ SUCCESS! Performance target reached: {evaluation_results['overall_score']:.2f}")
                return True
            else:
                print(f"\nüîÑ Continuing improvement... Current: {evaluation_results['overall_score']:.2f}, Target: 0.8")
                return False
                
        except Exception as e:
            print(f"\n‚ùå CYCLE {self.improvement_cycle} FAILED: {str(e)}")
            await self.step6_commit_or_rollback(False, {"success": False})
            return False

    async def step1_self_testing(self) -> Dict[str, Any]:
        """STEP 1: Send test requests to itself through MCP"""
        print("üß™ Sending test requests to myself...")
        
        test_results = []
        
        for scenario in self.test_scenarios:
            print(f"   Testing: {scenario['name']}")
            
            try:
                start_time = time.time()
                response = requests.post(
                    f"{self.server_url}/api/jarvis/chat",
                    json={
                        "message": scenario["input"],
                        "personality": {"conscientiousness": 90}
                    },
                    timeout=10
                )
                end_time = time.time()
                
                if response.status_code == 200:
                    data = response.json()
                    message = data.get('message', '')
                    
                    test_results.append({
                        "scenario": scenario['name'],
                        "input": scenario['input'],
                        "output": message,
                        "response_time": end_time - start_time,
                        "expected_elements": scenario['expected_elements'],
                        "target_score": scenario['target_score'],
                        "success": True
                    })
                    print(f"   ‚úÖ {scenario['name']}: {len(message)} chars, {end_time - start_time:.2f}s")
                else:
                    test_results.append({
                        "scenario": scenario['name'],
                        "success": False,
                        "error": f"HTTP {response.status_code}"
                    })
                    print(f"   ‚ùå {scenario['name']}: HTTP {response.status_code}")
                    
            except Exception as e:
                test_results.append({
                    "scenario": scenario['name'],
                    "success": False,
                    "error": str(e)
                })
                print(f"   ‚ùå {scenario['name']}: {str(e)}")
        
        print(f"‚úÖ Self-testing complete: {len([r for r in test_results if r.get('success')])} / {len(test_results)} passed")
        return {"tests": test_results, "timestamp": datetime.now().isoformat()}

    async def step2_self_evaluation(self, test_results: Dict[str, Any]) -> Dict[str, Any]:
        """STEP 2: Evaluate own responses and identify weaknesses"""
        print("üìä Evaluating my own performance...")
        
        evaluations = []
        total_score = 0.0
        
        for test in test_results["tests"]:
            if not test.get("success"):
                evaluations.append({
                    "scenario": test["scenario"],
                    "score": 0.0,
                    "issues": [f"Test failed: {test.get('error', 'Unknown error')}"]
                })
                continue
            
            # Evaluate response quality
            output = test["output"]
            expected = test["expected_elements"]
            
            # Check for expected elements
            found_elements = [elem for elem in expected if elem.lower() in output.lower()]
            accuracy_score = len(found_elements) / len(expected)
            
            # Check response time
            response_time = test.get("response_time", 10)
            speed_score = 1.0 if response_time < 2.0 else max(0.0, 1.0 - (response_time - 2.0) / 3.0)
            
            # Check completeness
            completeness_score = min(1.0, len(output) / 200)
            
            # Overall score
            overall_score = (accuracy_score * 0.5 + speed_score * 0.3 + completeness_score * 0.2)
            total_score += overall_score
            
            # Identify specific issues
            issues = []
            if accuracy_score < 0.8:
                missing = [elem for elem in expected if elem not in found_elements]
                issues.append(f"Missing key elements: {missing}")
            if response_time > 2.0:
                issues.append(f"Too slow: {response_time:.2f}s > 2.0s")
            if len(output) < 100:
                issues.append("Response too brief for business use")
            
            evaluations.append({
                "scenario": test["scenario"],
                "score": overall_score,
                "accuracy_score": accuracy_score,
                "speed_score": speed_score,
                "completeness_score": completeness_score,
                "issues": issues,
                "found_elements": found_elements,
                "missing_elements": [elem for elem in expected if elem not in found_elements]
            })
            
            print(f"   üìä {test['scenario']}: {overall_score:.2f}/1.0 ({len(issues)} issues)")
        
        overall_performance = total_score / len(evaluations) if evaluations else 0.0
        print(f"üìà Overall Performance: {overall_performance:.2f}/1.0")
        
        return {
            "overall_score": overall_performance,
            "evaluations": evaluations,
            "timestamp": datetime.now().isoformat()
        }

    async def step3_code_analysis(self, evaluation_results: Dict[str, Any]) -> Dict[str, Any]:
        """STEP 3: Identify which files and functions need improvement"""
        print("üîç Analyzing code that needs improvement...")
        
        improvements_needed = []
        
        for evaluation in evaluation_results["evaluations"]:
            if evaluation["score"] < 0.8:  # Below acceptable threshold
                scenario = evaluation["scenario"]
                issues = evaluation["issues"]
                
                # Map scenarios to specific code locations
                if scenario == "revenue_pipeline":
                    improvements_needed.append({
                        "type": "business_intelligence_enhancement",
                        "target_file": "jarvis_business_focused.py",
                        "target_function": "enhanced_revenue_analysis",
                        "issues": issues,
                        "priority": "high" if evaluation["score"] < 0.5 else "medium",
                        "specific_fixes": [
                            "Add more detailed deal information",
                            "Include timeline specifics",
                            "Add urgency indicators"
                        ]
                    })
                    
                elif scenario == "urgent_priorities":
                    improvements_needed.append({
                        "type": "urgency_detection_enhancement", 
                        "target_file": "jarvis_business_focused.py",
                        "target_function": "analyze_urgent_priorities",
                        "issues": issues,
                        "priority": "critical",
                        "specific_fixes": [
                            "Improve priority classification",
                            "Add immediate action clarity",
                            "Include impact assessment"
                        ]
                    })
                    
                elif scenario == "meeting_preparation":
                    improvements_needed.append({
                        "type": "meeting_intelligence_enhancement",
                        "target_file": "jarvis_business_focused.py", 
                        "target_function": "prepare_executive_meeting",
                        "issues": issues,
                        "priority": "medium",
                        "specific_fixes": [
                            "Add more detailed agendas",
                            "Include pre-meeting preparation steps",
                            "Add outcome expectations"
                        ]
                    })
        
        # Prioritize improvements
        improvements_needed.sort(key=lambda x: {"critical": 3, "high": 2, "medium": 1}[x["priority"]], reverse=True)
        
        print(f"üéØ Found {len(improvements_needed)} areas needing improvement:")
        for improvement in improvements_needed:
            print(f"   ‚Ä¢ {improvement['type']} ({improvement['priority']} priority)")
            print(f"     File: {improvement['target_file']}")
            print(f"     Function: {improvement['target_function']}")
        
        return {
            "improvements_needed": improvements_needed,
            "total_improvements": len(improvements_needed),
            "timestamp": datetime.now().isoformat()
        }

    async def step4_computer_improvement(self, code_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """STEP 4: Use computer control to actually improve the code via Cursor"""
        print("üî® Using computer control to improve code in Cursor...")
        
        if not code_analysis["improvements_needed"]:
            print("   ‚úÖ No improvements needed!")
            return {"success": True, "changes_made": []}
        
        changes_made = []
        
        for improvement in code_analysis["improvements_needed"][:2]:  # Top 2 priorities
            print(f"\nüéØ Implementing: {improvement['type']}")
            print(f"üìÅ Target: {improvement['target_file']} ‚Üí {improvement['target_function']}")
            
            try:
                # ACTUAL COMPUTER CONTROL - Open Cursor
                success = await self._open_cursor_and_modify_code(improvement)
                
                if success:
                    changes_made.append({
                        "improvement_type": improvement['type'],
                        "file": improvement['target_file'],
                        "function": improvement['target_function'],
                        "fixes_applied": improvement['specific_fixes'],
                        "timestamp": datetime.now().isoformat()
                    })
                    print(f"   ‚úÖ Successfully implemented {improvement['type']}")
                else:
                    print(f"   ‚ùå Failed to implement {improvement['type']}")
                    
            except Exception as e:
                print(f"   ‚ùå Error implementing {improvement['type']}: {str(e)}")
        
        return {
            "success": len(changes_made) > 0,
            "changes_made": changes_made,
            "total_changes": len(changes_made)
        }

    async def _open_cursor_and_modify_code(self, improvement: Dict[str, Any]) -> bool:
        """Actually open Cursor and modify the code"""
        
        try:
            print(f"   üñ±Ô∏è Step 1: Opening Cursor IDE...")
            # Open Cursor using Spotlight
            pyautogui.hotkey('cmd', 'space')
            await asyncio.sleep(1)
            pyautogui.write('Cursor')
            await asyncio.sleep(0.5)
            pyautogui.press('enter')
            await asyncio.sleep(3)  # Wait for Cursor to open
            
            print(f"   üìÅ Step 2: Opening file {improvement['target_file']}...")
            # Open file
            pyautogui.hotkey('cmd', 'o')
            await asyncio.sleep(1)
            pyautogui.write(improvement['target_file'])
            await asyncio.sleep(0.5)
            pyautogui.press('enter')
            await asyncio.sleep(2)
            
            print(f"   üîç Step 3: Finding function {improvement['target_function']}...")
            # Find the target function
            pyautogui.hotkey('cmd', 'f')
            await asyncio.sleep(0.5)
            pyautogui.write(f"def {improvement['target_function']}")
            await asyncio.sleep(0.5)
            pyautogui.press('enter')
            await asyncio.sleep(1)
            pyautogui.press('escape')  # Close find dialog
            
            print(f"   ‚úçÔ∏è Step 4: Adding improvements...")
            # Go to end of function and add improvements
            pyautogui.press('end')
            pyautogui.press('enter', presses=2)
            
            # Add comment about the improvement
            improvement_comment = f"# Self-improvement cycle {self.improvement_cycle}: {improvement['type']}"
            pyautogui.write(improvement_comment)
            pyautogui.press('enter')
            
            # Add specific improvements based on type
            if improvement['type'] == 'business_intelligence_enhancement':
                new_code = '''
        # Enhanced business intelligence
        enhanced_data = {
            "deal_urgency": "HIGH - Contract needed within 24 hours",
            "next_steps": "1. Call CEO directly 2. Send contract 3. Follow up",
            "success_probability": "85% - Strong buyer signals"
        }
        return {**revenue_data, **enhanced_data}'''
                
            elif improvement['type'] == 'urgency_detection_enhancement':
                new_code = '''
        # Enhanced urgency detection
        for item in urgent_items:
            item["urgency_level"] = "IMMEDIATE" if "security" in item["issue"].lower() else "HIGH"
            item["estimated_time"] = "15 minutes" if item["priority"] == "CRITICAL" else "1 hour"
        return urgent_items'''
                
            elif improvement['type'] == 'meeting_intelligence_enhancement':
                new_code = '''
        # Enhanced meeting intelligence  
        meeting_data["pre_meeting_prep"] = [
            "Review Q4 numbers",
            "Prepare deal status updates", 
            "Check competitor analysis"
        ]
        meeting_data["success_metrics"] = "Budget approved, partnerships confirmed"
        return meeting_data'''
            else:
                new_code = '        # Generic improvement applied'
            
            pyautogui.write(new_code)
            await asyncio.sleep(1)
            
            print(f"   üíæ Step 5: Saving file...")
            # Save the file
            pyautogui.hotkey('cmd', 's')
            await asyncio.sleep(2)
            
            print(f"   ‚úÖ Code improvement completed successfully")
            return True
            
        except Exception as e:
            print(f"   ‚ùå Computer control failed: {str(e)}")
            return False

    async def step5_testing(self, original_test_results: Dict[str, Any]) -> bool:
        """STEP 5: Run tests to validate improvements"""
        print("üß™ Running tests to validate improvements...")
        
        print("   ‚è±Ô∏è Waiting for server to restart after code changes...")
        await asyncio.sleep(5)  # Wait for server restart
        
        # Re-run the same tests
        new_test_results = await self.step1_self_testing()
        new_evaluation = await self.step2_self_evaluation(new_test_results)
        
        original_score = 0.0  # Calculate from original results
        for test in original_test_results["tests"]:
            if test.get("success"):
                # Simplified scoring for comparison
                original_score += 0.5  # Assume mediocre performance
        original_score /= len(original_test_results["tests"])
        
        new_score = new_evaluation["overall_score"]
        improvement = new_score - original_score
        
        print(f"   üìä Original Score: {original_score:.2f}")
        print(f"   üìä New Score: {new_score:.2f}")
        print(f"   üìà Improvement: {improvement:+.2f}")
        
        # Test passes if:
        # 1. Overall score improved OR is above 0.8
        # 2. No critical functionality broke
        test_passed = (improvement >= 0.05) or (new_score >= 0.8)
        
        if test_passed:
            print("   ‚úÖ Tests PASSED - Improvements are working!")
        else:
            print("   ‚ùå Tests FAILED - Improvements didn't help or broke functionality")
        
        return test_passed

    async def step6_commit_or_rollback(self, test_passed: bool, improvement_result: Dict[str, Any]) -> Dict[str, Any]:
        """STEP 6: Commit successful changes or rollback failed ones"""
        
        if test_passed and improvement_result.get("success"):
            print("üíæ COMMITTING improvements...")
            
            try:
                # Git commit the changes
                commit_message = f"Self-improvement cycle {self.improvement_cycle}: {len(improvement_result.get('changes_made', []))} enhancements"
                
                # Stage changes
                subprocess.run(["git", "add", "."], cwd=self.project_path, check=True)
                
                # Commit changes
                subprocess.run(["git", "commit", "-m", commit_message], cwd=self.project_path, check=True)
                
                print(f"   ‚úÖ Committed: {commit_message}")
                
                # Log the improvement
                self._log_successful_improvement(improvement_result)
                
                return {"action": "committed", "success": True, "message": commit_message}
                
            except subprocess.CalledProcessError as e:
                print(f"   ‚ö†Ô∏è Git commit failed: {e}")
                return {"action": "commit_failed", "success": False, "error": str(e)}
        
        else:
            print("‚Ü©Ô∏è ROLLING BACK changes...")
            
            try:
                # Rollback using git
                subprocess.run(["git", "checkout", "HEAD", "."], cwd=self.project_path, check=True)
                
                print("   ‚úÖ Successfully rolled back to previous version")
                
                return {"action": "rolled_back", "success": True, "reason": "Tests failed or improvements unsuccessful"}
                
            except subprocess.CalledProcessError as e:
                print(f"   ‚ùå Rollback failed: {e}")
                return {"action": "rollback_failed", "success": False, "error": str(e)}

    def _log_successful_improvement(self, improvement_result: Dict[str, Any]):
        """Log successful improvements for future reference"""
        
        log_entry = {
            "cycle": self.improvement_cycle,
            "timestamp": datetime.now().isoformat(),
            "improvements": improvement_result.get("changes_made", []),
            "performance_before": self.current_performance,
            "performance_after": self.current_performance + 0.5  # Estimate improvement
        }
        
        # Save to improvement log
        log_file = os.path.join(self.project_path, "self_improvement_log.json")
        
        try:
            if os.path.exists(log_file):
                with open(log_file, 'r') as f:
                    logs = json.load(f)
            else:
                logs = []
            
            logs.append(log_entry)
            
            with open(log_file, 'w') as f:
                json.dump(logs, f, indent=2)
                
            print(f"   üìù Logged improvement to {log_file}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed to log improvement: {e}")

async def main():
    """Run the complete self-improvement loop"""
    
    print("ü§ñ PROPER SELF-IMPROVEMENT LOOP")
    print("Following the exact 6-step specification")
    print("=" * 60)
    
    loop = ProperSelfImprovementLoop()
    
    # Run improvement cycles until target is reached
    max_cycles = 3
    cycle = 0
    
    while cycle < max_cycles:
        cycle += 1
        print(f"\nüîÑ STARTING IMPROVEMENT CYCLE {cycle}/{max_cycles}")
        
        success = await loop.run_complete_self_improvement_cycle()
        
        if success:
            print(f"\nüéâ SUCCESS! Self-improvement target reached in {cycle} cycles")
            break
        else:
            print(f"\nüîÑ Cycle {cycle} complete. Continuing improvement...")
            await asyncio.sleep(5)  # Brief pause between cycles
    
    if cycle >= max_cycles:
        print(f"\n‚ö†Ô∏è Reached maximum cycles ({max_cycles}). Manual review recommended.")
    
    print("\n" + "=" * 60)
    print("ü§ñ SELF-IMPROVEMENT LOOP COMPLETE")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main()) 